{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train classifier based on semi-supervised labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-30T18:26:18.612066Z",
     "start_time": "2018-06-30T18:26:18.598052Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import copy\n",
    "\n",
    "import random\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, train_test_split\n",
    "from sklearn.metrics import classification_report, recall_score\n",
    "from sklearn.pipeline import Pipeline \n",
    "\n",
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "from nltk.tokenize import sent_tokenize, PunktSentenceTokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-30T18:35:03.776486Z",
     "start_time": "2018-06-30T18:35:03.603221Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('data/classifier_input_train.csv', index_col=0)\n",
    "train_df = train_df[train_df.len > 19]\n",
    "val_df = pd.read_csv('data/classifier_input_val.csv', index_col=0)\n",
    "val_df = val_df[val_df.len > 19]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenize dollar values as dollar tokens, numerics as numeric tokens, but leave years as they are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-30T18:23:23.548403Z",
     "start_time": "2018-06-30T18:23:23.539396Z"
    }
   },
   "outputs": [],
   "source": [
    "year_pat = re.compile(r\"([^0-9])((?:20|19)[0,1,2,9][0-9])([^0-9])\")\n",
    "dollar_pat = re.compile(r\"[$]([0-9]{1,3},)*[0-9]{1,3}[.]?[0-9]{,4}\")\n",
    "num_pat = re.compile(\n",
    "r\"(y(?:20|19)[0,1,2,9][0-9])|(?:(?P<bound1>[\\s,.])(?:(?:[0-9]{1,3}[,])*(?:[0-9]{1,3}))(?:[.][0-9]{1,4})?[%]?(?P<bound2>[\\s,.]))\")\n",
    "year_fix_pat = re.compile(r\"y((?:20|19)[0,1,2,9][0-9])num_tok\")\n",
    "\n",
    "def replace_numeric_toks(s):\n",
    "    s1 = re.sub(year_pat, r'\\1y\\2\\3', s )\n",
    "    s2 = re.sub(dollar_pat, r'dollar_tok', s1)\n",
    "    s3 = re.sub(num_pat, r'\\1\\g<bound1>num_tok\\g<bound2>', s2)\n",
    "    s4 = re.sub(year_fix_pat, r'\\1', s3)\n",
    "    return s4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-30T18:23:26.909912Z",
     "start_time": "2018-06-30T18:23:26.902907Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_x_text(df, text_col = 'para_text', text_prep_func = replace_numeric_toks):\n",
    "    \"\"\"Return column of text ready for vectorization\"\"\"\n",
    "    x_text = df[text_col].apply(text_prep_func)\n",
    "    return x_text\n",
    "\n",
    "def get_x_y(df, x_cols = ['para_text'], y_col = 'label'):\n",
    "    \"\"\"Split df into X,y, performing transformations as needed\"\"\"\n",
    "    X_text = get_x_text(df)\n",
    "    y = df[y_col]\n",
    "    X =X_text \n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-30T18:36:25.768653Z",
     "start_time": "2018-06-30T18:36:25.314582Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, y_train = get_x_y(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-30T18:48:19.466210Z",
     "start_time": "2018-06-30T18:48:19.310172Z"
    }
   },
   "outputs": [],
   "source": [
    "X_val, y_val = get_x_y(val_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to cross-validate models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-30T18:26:36.018835Z",
     "start_time": "2018-06-30T18:26:36.013832Z"
    }
   },
   "outputs": [],
   "source": [
    "def cv_acc(model, X, y, cv=5, scoring='accuracy'):\n",
    "    cv_dict = {}\n",
    "    cvs = cross_val_score(model, X, y, cv=cv, scoring=scoring)\n",
    "    cv_dict['cv_mean'] = np.mean(cvs)\n",
    "    cv_dict['cvs'] = cvs\n",
    "    return cv_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-30T18:26:37.048506Z",
     "start_time": "2018-06-30T18:26:37.045501Z"
    }
   },
   "outputs": [],
   "source": [
    "model_params_dict = {}\n",
    "model_cvs = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-30T18:27:28.144397Z",
     "start_time": "2018-06-30T18:27:28.134390Z"
    }
   },
   "outputs": [],
   "source": [
    "count_vec = CountVectorizer(ngram_range=(1,6), max_df=0.6, min_df=.025, max_features=5000)\n",
    "bin_vec = CountVectorizer(ngram_range=(1,6), max_df=0.2, min_df=.01, binary=True, max_features=5000)\n",
    "tfidf_vec = TfidfVectorizer(ngram_range=(1,6), max_df=0.62, min_df=.025, max_features=5000)\n",
    "\n",
    "# Define a pipeline combining a text feature extractor with a simple\n",
    "# classifier\n",
    "\n",
    "# Logistic Regression \n",
    "\n",
    "lr_bin_pl = Pipeline([\n",
    "    ('vec', bin_vec),\n",
    "    ('lr', LogisticRegression(random_state=14, max_iter=1000))\n",
    "])\n",
    "\n",
    "lr_count_pl = Pipeline([\n",
    "    ('vec', count_vec),\n",
    "    ('lr', LogisticRegression(random_state=14, max_iter=1000))\n",
    "])\n",
    "\n",
    "lr_tfidf_pl = Pipeline([\n",
    "    ('vec', tfidf_vec),\n",
    "    ('lr', LogisticRegression(random_state=14, max_iter=1000))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-30T18:49:30.578802Z",
     "start_time": "2018-06-30T18:49:30.573800Z"
    }
   },
   "outputs": [],
   "source": [
    "    # Result: \n",
    "#    'vec__max_df': (.5, .75, .9), \n",
    "#    'vec__min_df': (.01, .05, .10, .20),\n",
    "#    'vec__ngram_range' : [(1,6)]\n",
    "\n",
    "    # {'vec__max_df': 0.9, 'vec__min_df': 0.01, 'vec__ngram_range': (1, 6)}\n",
    "# max GS test score: 0.908048417923126\n",
    "#{'cv_mean': 0.8742884854235194, 'cvs': array([0.86956522, 0.87685775, 0.8566879 , 0.89904357, 0.86928799])}\n",
    "# val score: 0.9275747508305647\n",
    "param_grid_bin = {\n",
    "    'vec__max_df': (.9, .95), \n",
    "    'vec__min_df': (.005, .01),\n",
    "    'vec__ngram_range' : [(1,5), (1,6), (1,7), (1,8)]\n",
    "\n",
    "    \n",
    "    #'vec__ngram_range' : [(1,5), (1,6), (1,7)]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-30T18:49:42.688792Z",
     "start_time": "2018-06-30T18:49:42.685790Z"
    }
   },
   "outputs": [],
   "source": [
    "lr_bin_gs = GridSearchCV(lr_bin_pl, param_grid=param_grid_bin, cv=4, return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-30T18:58:23.205194Z",
     "start_time": "2018-06-30T18:50:03.285990Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=4, error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('vec', CountVectorizer(analyzer='word', binary=True, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=0.9, max_features=5000, min_df=0.01,\n",
       "        ngram_range=(1, 6), preprocessor=None, stop_words=None,\n",
       "        stri...alty='l2', random_state=14, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False))]),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'vec__max_df': (0.9, 0.95), 'vec__min_df': (0.005, 0.01), 'vec__ngram_range': [(1, 5), (1, 6), (1, 7), (1, 8)]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_bin_gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-30T19:00:35.951115Z",
     "start_time": "2018-06-30T19:00:35.946113Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9125079634741984"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_bin_gs.cv_results_['mean_test_score'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-30T19:00:38.095684Z",
     "start_time": "2018-06-30T19:00:38.090680Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'vec__max_df': 0.9, 'vec__min_df': 0.005, 'vec__ngram_range': (1, 5)}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Best hyperparameter settings, which were found by the GridSearchCV - want to keep this:\n",
    "model_params_dict['lr_bin'] = lr_bin_gs.best_params_\n",
    "lr_bin_gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-30T18:49:04.019606Z",
     "start_time": "2018-06-30T18:48:57.230216Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vec', CountVectorizer(analyzer='word', binary=True, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=0.9, max_features=5000, min_df=0.01,\n",
       "        ngram_range=(1, 6), preprocessor=None, stop_words=None,\n",
       "        stri...alty='l2', random_state=14, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_bin_pl.set_params(**model_params_dict['lr_bin'])\n",
    "lr_bin_pl.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get and print model cross validation scores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-30T18:47:55.941733Z",
     "start_time": "2018-06-30T18:47:27.751370Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cv_mean': 0.8742884854235194, 'cvs': array([0.86956522, 0.87685775, 0.8566879 , 0.89904357, 0.86928799])}\n"
     ]
    }
   ],
   "source": [
    "model_cvs['lr_bin'] = cv_acc(lr_bin_pl, X_train, y_train)\n",
    "print(model_cvs['lr_bin'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Against the unseen holdout/validation set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-30T18:49:19.717168Z",
     "start_time": "2018-06-30T18:49:19.041301Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9275747508305647"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_bin_pl.score(X_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TfIdf Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-30T18:31:06.183898Z",
     "start_time": "2018-06-30T18:31:06.179894Z"
    }
   },
   "outputs": [],
   "source": [
    "param_grid_tfidf = {\n",
    "    'vec__max_df': (0.5, .7, .9),\n",
    "    'vec__min_df': (.005, .01, .015, .025),\n",
    "    'vec__ngram_range' : [(1,6)]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-30T18:49:42.688792Z",
     "start_time": "2018-06-30T18:49:42.685790Z"
    }
   },
   "outputs": [],
   "source": [
    "lr_tfidf_gs = GridSearchCV(lr_tfidf_pl, param_grid=param_grid_tfidf, cv=4, return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_tfidf_gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-30T18:43:21.779924Z",
     "start_time": "2018-06-30T18:43:21.759911Z"
    }
   },
   "outputs": [],
   "source": [
    "lr_tfidf_gs.['mean_test_score'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best hyperparameter settings, which were found by the GridSearchCV - want to keep this:\n",
    "model_params_dict['lr_tfidf'] = lr_tfidf_gs.best_params_\n",
    "lr_tfidf_gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_tfidf_pl.set_params(**model_params_dict['lr_tfidf'])\n",
    "lr_tfidf_pl.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cvs['lr_tfidf'] = cv_acc(lr_tfidf_pl, X_train, y_train)\n",
    "print(model_cvs['lr_tfidf'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions and results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lr_bin_pl.predict(X_train)\n",
    "y_val_pred = lr_bin_pl.predict(X_val)\n",
    "y_proba = lr_bin_pl.predict_proba(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_val, y_val_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
